{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pickle.load(open('datasets.pickle', 'rb'))\n",
    "\n",
    "\n",
    "batchsize = 32\n",
    "trainset = dataset[0]\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize, shuffle=True)\n",
    "valset = dataset[1]\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batchsize, shuffle=False)  # Disable shuffling\n",
    "testset = dataset[2]\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batchsize, shuffle=False)  # Disable shuffling\n",
    "\n",
    "input_dim = 4\n",
    "output_dim = trainset[0][1].shape[0]\n",
    "\n",
    "class MLP(pl.LightningModule):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(MLP, self).__init__()\n",
    "        self.emb1 = torch.nn.Embedding(100000, 32)\n",
    "        self.emb2 = torch.nn.Embedding(100000, 32)\n",
    "        self.timeday = torch.nn.Linear(2, 32)\n",
    "        self.class1 = torch.nn.Linear(96, hidden_channels)\n",
    "        \n",
    "        self.class2 = torch.nn.Linear(hidden_channels, 32)\n",
    "       \n",
    "        self.class3 = torch.nn.Linear(32, 16)\n",
    "        \n",
    "        self.class4 = torch.nn.Linear(16, out_channels)\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.test_losses = []\n",
    "        self.train_acc_at_k = []\n",
    "        self.val_acc_at_k = []\n",
    "        self.test_acc_at_k = []\n",
    "        self.train_mrr = []\n",
    "        self.val_mrr = []\n",
    "        self.test_mrr = []\n",
    "        self.epochs_trained = 0\n",
    "\n",
    "    def forward(self, data):\n",
    "        user = self.emb1(data[:, 0])\n",
    "        loc = self.emb2(data[:, 1])\n",
    "        hour = data[:, 2]\n",
    "        day = data[:, 3]\n",
    "        timeday = torch.stack([hour, day], dim=-1)\n",
    "        timeday = self.timeday(timeday.float())\n",
    "        x = torch.cat((user, loc, timeday), dim=1)\n",
    "        x = self.class1(x).relu()\n",
    "        \n",
    "        x = self.class2(x).relu()\n",
    "        \n",
    "        x = self.class3(x).relu()\n",
    "        \n",
    "        x = self.class4(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input = batch[0]\n",
    "        target = batch[1]\n",
    "        output = self(input[:, :4])\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        acc_at_k_value = self.accuracy_at_k(output, target, k=5)\n",
    "        mrr_value = self.mean_reciprocal_rank(output, target)\n",
    "        self.log('train_loss', loss, on_epoch=True, on_step=False)\n",
    "        self.log('train_acc_at_k', acc_at_k_value, on_epoch=True, on_step=False)\n",
    "        self.log('train_mrr', mrr_value, on_epoch=True, on_step=False)\n",
    "\n",
    "        # Debug statements\n",
    "        print(f\"Epoch {self.current_epoch} Training loss: {loss.item()} Accuracy@k: {acc_at_k_value.item()} MRR: {mrr_value.item()}\")\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input = batch[0]\n",
    "        target = batch[1]\n",
    "        output = self(input[:, :4])\n",
    "        val_loss = F.cross_entropy(output, target)\n",
    "        acc_at_k = self.accuracy_at_k(output, target, k=5)\n",
    "        mrr = self.mean_reciprocal_rank(output, target)\n",
    "        self.log('val_loss', val_loss, on_epoch=True, on_step=False)\n",
    "        self.log('val_acc_at_k', acc_at_k, on_epoch=True, on_step=False)\n",
    "        self.log('val_mrr', mrr, on_epoch=True, on_step=False)\n",
    "\n",
    "        # Debug statements\n",
    "        print(f\"Epoch {self.current_epoch} Validation loss: {val_loss.item()} Accuracy@k: {acc_at_k.item()} MRR: {mrr.item()}\")\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input = batch[0]\n",
    "        target = batch[1]\n",
    "        output = self(input[:, :4])\n",
    "        test_loss = F.cross_entropy(output, target)\n",
    "        acc_at_k = self.accuracy_at_k(output, target, k=5)\n",
    "        mrr = self.mean_reciprocal_rank(output, target)\n",
    "        self.log('test_loss', test_loss)\n",
    "        self.log('test_acc_at_k', acc_at_k)\n",
    "        self.log('test_mrr', mrr)\n",
    "        self.test_losses.append(test_loss.item())\n",
    "        self.test_acc_at_k.append(acc_at_k.item())\n",
    "        self.test_mrr.append(mrr.item())\n",
    "\n",
    "        # Debug statements\n",
    "        print(f\"Test loss: {test_loss.item()} Accuracy@k: {acc_at_k.item()} MRR: {mrr.item()}\")\n",
    "\n",
    "        return test_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "        return optimizer\n",
    "\n",
    "    def accuracy_at_k(self, y_pred, y_true, k=10):\n",
    "        _, top_k = y_pred.topk(k, dim=1)\n",
    "        _, label = y_true.topk(1, dim=1)\n",
    "        correct = top_k.eq(label.view(-1, 1).expand_as(top_k))\n",
    "        acc_at_k = correct.float().sum(dim=1).mean()\n",
    "        return acc_at_k\n",
    "\n",
    "    def mean_reciprocal_rank(self, y_pred, y_true):\n",
    "        _, rank = y_pred.sort(dim=1, descending=True)\n",
    "        rank = rank.argsort(dim=1)\n",
    "        _, label = y_true.topk(1, dim=1)\n",
    "        rr = (1.0 / (rank.gather(1, label.view(-1, 1).long()) + 1)).mean()\n",
    "        return rr\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Collect training metrics once per epoch\n",
    "        epoch_loss = self.trainer.callback_metrics['train_loss']\n",
    "        epoch_acc_at_k = self.trainer.callback_metrics['train_acc_at_k']\n",
    "        epoch_mrr = self.trainer.callback_metrics['train_mrr']\n",
    "        self.train_losses.append(epoch_loss.item())\n",
    "        self.train_acc_at_k.append(epoch_acc_at_k.item())\n",
    "        self.train_mrr.append(epoch_mrr.item())\n",
    "\n",
    "        print(f\"End of epoch {self.current_epoch} - Training loss: {epoch_loss.item()}, Accuracy@k: {epoch_acc_at_k.item()}, MRR: {epoch_mrr.item()}\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Collect validation metrics once per epoch\n",
    "        epoch_val_loss = self.trainer.callback_metrics['val_loss']\n",
    "        epoch_val_acc_at_k = self.trainer.callback_metrics['val_acc_at_k']\n",
    "        epoch_val_mrr = self.trainer.callback_metrics['val_mrr']\n",
    "        self.val_losses.append(epoch_val_loss.item())\n",
    "        self.val_acc_at_k.append(epoch_val_acc_at_k.item())\n",
    "        self.val_mrr.append(epoch_val_mrr.item())\n",
    "\n",
    "        print(f\"End of epoch {self.current_epoch} - Validation loss: {epoch_val_loss.item()}, Accuracy@k: {epoch_val_acc_at_k.item()}, MRR: {epoch_val_mrr.item()}\")\n",
    "\n",
    "class MetricsLengthCallback(Callback):\n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        print(f\"Epoch {trainer.current_epoch} - Training losses length: {len(pl_module.train_losses)}, Validation losses length: {len(pl_module.val_losses)}\")\n",
    "\n",
    "numepoch = 200\n",
    "\n",
    "model = MLP(input_dim, 64, output_dim)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=numepoch,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(monitor='train_loss'),\n",
    "        EarlyStopping(monitor='train_loss', patience=10),\n",
    "        MetricsLengthCallback()  # Add the custom callback here\n",
    "    ]\n",
    ")\n",
    "trainer.fit(model, trainloader, valloader)\n",
    "\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Check the lengths of the lists after training\n",
    "print(f\"Final Training losses length: {len(model.train_losses)}\")\n",
    "print(f\"Final Validation losses length: {len(model.val_losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_result = trainer.test(model, dataloaders=testloader)[0]\n",
    "test_losses = model.test_losses\n",
    "train_losses = model.train_losses\n",
    "val_losses = model.val_losses\n",
    "print(f\"Test Loss: {test_result['test_loss']}\")\n",
    "print(f\"Test Accuracy@5: {test_result['test_acc_at_k']}\")\n",
    "print(f\"Test MRR: {test_result['test_mrr']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
